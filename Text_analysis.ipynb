{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdw4aMJsmsAo8HAcHOGITw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paupinedo/mars/blob/master/Text_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHZkoQU87tQN"
      },
      "source": [
        "# Spacy Workshop\n",
        "This is where I'm going to annotate what I'm doing in SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBPnqQu_7oTX",
        "outputId": "a86eba98-a9ab-443f-aa71-a76e2a4ef677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Hello world')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NB4rPJ67-8q"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at7HFGhI8Okq"
      },
      "source": [
        "then we need to download a language model fom https://spacy.io/usage/models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR0WJTVZ85R1",
        "outputId": "e554c63e-bcab-4990-8ceb-ec579b58e7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "spacy.cli.download('en_core_web_md')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z8pb1ah9Cny"
      },
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1GXUjCG_XbX"
      },
      "source": [
        "## Let's get some texts\n",
        "### use the nltk built-in test text corpora. The nltk is a built-in library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3GoX1fM9cEo",
        "outputId": "4b28ec8f-c0e4-406b-a503-e3d3e53843ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "nltk.download('book')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l96BTzET-BmH"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lqwakrN_tzR"
      },
      "source": [
        "### get text from the gutenberg corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCipCI-R-LlB",
        "outputId": "92a7a2e7-d482-4459-b0e0-5aba7ecf0a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwlonPI9ABBX"
      },
      "source": [
        "To get text that is in my computer we just need to say:\n",
        "open('file name').read()\n",
        "Plane text works teh best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taKAqQQzA4Qz"
      },
      "source": [
        "### lets work with alice in wonderland. lets assign it a name: alice and then get it from the gutenberg corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5J_eg5wAg4p"
      },
      "source": [
        "alice = nltk.corpus.gutenberg.raw('carroll-alice.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAaBBI0IBEHD"
      },
      "source": [
        "#### now let's take a look at the first 200 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoQ5FjsxAyr8",
        "outputId": "4f67ae69-aeef-476d-8f44-ea08ff9dd86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "alice[:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDQ5iCfnBZ3_"
      },
      "source": [
        "### If we want to get Alice in wonderland from the Internet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCSUfub9CDIh"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27lfaWzMBf9R"
      },
      "source": [
        "aliceUrl = 'http://www.gutenberg.org/files/11/11-0.txt'\n",
        "alice = requests.get(aliceUrl).text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDX8KeezCQBt",
        "outputId": "12ae865a-22ea-40d1-c0eb-344bbf0d55d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice.index('CHAPTER')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lDeoNx2CgxU",
        "outputId": "084ec944-9771-4ed6-e3b9-96f45e2e3e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alice.index('THE END')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy2HHIx_Clpv"
      },
      "source": [
        "aliceClean = alice[816:155145]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ1cESfVCrmf",
        "outputId": "938d7731-6213-48f8-9b2b-85abd36a5892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(aliceClean[:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHAPTER I.     Down the Rabbit-Hole\r\n",
            " CHAPTER II.    The Pool of Tears\r\n",
            " CHAPTER III.   A Caucus-Race and a Long Tale\r\n",
            " CHAPTER IV.    The Rabbit Sends in a Little Bill\r\n",
            " CHAPTER V.     Advice from a \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XinzVCJ9EWbu"
      },
      "source": [
        "### Now we parse it with SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSoXljg_Cvq1"
      },
      "source": [
        "aliceDoc = nlp(aliceClean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etez1aAdEmk5"
      },
      "source": [
        "To see all of the things we can do with the SpaCy doc:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFgMFDKzEegE",
        "outputId": "0b2eee41-947c-42f1-b58c-7ba440bf5c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(aliceDoc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " '_bulk_merge',\n",
              " '_py_tokens',\n",
              " '_realloc',\n",
              " '_vector',\n",
              " '_vector_norm',\n",
              " 'cats',\n",
              " 'char_span',\n",
              " 'count_by',\n",
              " 'doc',\n",
              " 'ents',\n",
              " 'extend_tensor',\n",
              " 'from_array',\n",
              " 'from_bytes',\n",
              " 'from_disk',\n",
              " 'get_extension',\n",
              " 'get_lca_matrix',\n",
              " 'has_extension',\n",
              " 'has_vector',\n",
              " 'is_nered',\n",
              " 'is_parsed',\n",
              " 'is_sentenced',\n",
              " 'is_tagged',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'mem',\n",
              " 'merge',\n",
              " 'noun_chunks',\n",
              " 'noun_chunks_iterator',\n",
              " 'print_tree',\n",
              " 'remove_extension',\n",
              " 'retokenize',\n",
              " 'sentiment',\n",
              " 'sents',\n",
              " 'set_extension',\n",
              " 'similarity',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'to_array',\n",
              " 'to_bytes',\n",
              " 'to_disk',\n",
              " 'to_json',\n",
              " 'to_utf8_array',\n",
              " 'user_data',\n",
              " 'user_hooks',\n",
              " 'user_span_hooks',\n",
              " 'user_token_hooks',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk8o7a8EFAkI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJPATMmfFCbj"
      },
      "source": [
        "## Tokenizing\n",
        "Means breaking up a text into parts that are asy to manipulate with a computer. e.g. se ntences, paragraphs, words. \n",
        "Token examples : space, punctuation mark, or a word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_s7eFCVFmmh",
        "outputId": "e743e1c9-74f7-4b4d-843a-4499119653ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(aliceDoc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4MiArQyF6YZ",
        "outputId": "9285bc95-2c9c-4a63-cee5-a99935030dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "aliceDoc[500:600]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "she found herself falling down a very\n",
              "deep well.\n",
              "\n",
              "Either the well was very deep, or she fell very slowly, for she had\n",
              "plenty of time as she went down to look about her and to wonder what\n",
              "was going to happen next. First, she tried to look down and make out\n",
              "what she was coming to, but it was too dark to see anything; then she\n",
              "looked at the sides of the well, and noticed that they were filled with\n",
              "cupboards and book-"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-_VeaGOGDSi",
        "outputId": "bd952588-2478-483c-f0da-964b05415d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "aliceDoc[507]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT__4LAKGIj3",
        "outputId": "d9d12712-805a-415c-f2f0-579e5e07f877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "#Enumerate ['a', 'b', 'c'] => [(0,'a'), (1,'b'), (2, 'c')]\n",
        "for tokenIndex, token in enumerate(aliceDoc[500;550]):\n",
        "  print(tokenIndex, token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-4fe7025d177b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for tokenIndex, token in enumerate(aliceDoc[500;550]):\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdW3SrRIG5CR",
        "outputId": "8592b576-6545-458a-817f-ddeb87c91b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "list(aliceDoc.sents) [100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "she looked up, but it was all dark overhead; before her was another\n",
              "long passage, and the White Rabbit was still in sight, hurrying down\n",
              "it."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osvmtiGYHYZP"
      },
      "source": [
        "How many sentences are in Alice in Wonderlan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RSpe9oaHBBD",
        "outputId": "0c0c2e3a-4ea1-4d9f-dfe7-b22a77e8e94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(list(aliceDoc.sents))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suTjPzWGHjIH"
      },
      "source": [
        "sent100=list(aliceDoc.sents)[100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ISlzRDIHpGA",
        "outputId": "5b705bf7-19be-4f70-b19a-3715c7697090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(sent100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIz2OGDlHs-H",
        "outputId": "1d5a6f7d-50e8-4488-f91b-9ef159ff7645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "for word in sent100:\n",
        "  print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "she\n",
            "looked\n",
            "up\n",
            ",\n",
            "but\n",
            "it\n",
            "was\n",
            "all\n",
            "dark\n",
            "overhead\n",
            ";\n",
            "before\n",
            "her\n",
            "was\n",
            "another\n",
            "\r\n",
            "\n",
            "long\n",
            "passage\n",
            ",\n",
            "and\n",
            "the\n",
            "White\n",
            "Rabbit\n",
            "was\n",
            "still\n",
            "in\n",
            "sight\n",
            ",\n",
            "hurrying\n",
            "down\n",
            "\r\n",
            "\n",
            "it\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcFKIksuHzZ0"
      },
      "source": [
        "she = sent100[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be2k16mxH6wy",
        "outputId": "dbf452e3-9281-4337-b285-206a1bc41b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(she)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_extension',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'string',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4DOMjQpIKbv"
      },
      "source": [
        "### lemmatizing function:\n",
        "go, goes, went, going =>go\n",
        "photograohy, phptographer =>photo\n",
        "jump, jumped => jump\n",
        "It just collapses the same combination of words into the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_c_d_JzIfDN",
        "outputId": "56a72f52-9beb-4198-9f55-3aaf9632d7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#e.g. here it says she is a pronound,. It will count as a pronound whe counting it\n",
        "she.lemma_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'-PRON-'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SSx9urIpyx",
        "outputId": "6698fc46-d883-4d3e-9828-c8abe5719aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "she.pos_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PRON'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QGIkXSItYT"
      },
      "source": [
        "Part-of-speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBUVRjjfIwlR",
        "outputId": "6ce2656a-0822-415c-8d62-e98154a5f943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "for token in sent100:\n",
        "  print(token, token.pos_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "she PRON\n",
            "looked VERB\n",
            "up ADP\n",
            ", PUNCT\n",
            "but CCONJ\n",
            "it PRON\n",
            "was AUX\n",
            "all DET\n",
            "dark ADJ\n",
            "overhead NOUN\n",
            "; PUNCT\n",
            "before ADP\n",
            "her PRON\n",
            "was AUX\n",
            "another DET\n",
            "\r\n",
            " SPACE\n",
            "long ADJ\n",
            "passage NOUN\n",
            ", PUNCT\n",
            "and CCONJ\n",
            "the DET\n",
            "White PROPN\n",
            "Rabbit PROPN\n",
            "was AUX\n",
            "still ADV\n",
            "in ADP\n",
            "sight NOUN\n",
            ", PUNCT\n",
            "hurrying VERB\n",
            "down ADP\n",
            "\r\n",
            " SPACE\n",
            "it PRON\n",
            ". PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRBESpyHI3kI"
      },
      "source": [
        "#geta. list of all teh adjectives in the whole documnet\n",
        "aliceAdjs = [token.lemma_ for token in aliceDoc if token.pos_ =='ADJ']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc9sW1GWJMGD",
        "outputId": "407c39be-d9f1-4cc9-b685-84b7c6d8c9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#to print the adjectives between 300 and 400 words\n",
        "aliceAdjs[300:400]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['long',\n",
              " 'more',\n",
              " 'other',\n",
              " 'offended',\n",
              " 'good',\n",
              " 'dry',\n",
              " 'inclined',\n",
              " 'good',\n",
              " 'exact',\n",
              " 'easy',\n",
              " 'dry',\n",
              " 'great',\n",
              " 'long',\n",
              " 'last',\n",
              " 'whole',\n",
              " 'crowded',\n",
              " 'confused',\n",
              " 'elegant',\n",
              " 'short',\n",
              " 'whole',\n",
              " 'absurd',\n",
              " 'grave',\n",
              " 'solemn',\n",
              " 'next',\n",
              " 'large',\n",
              " 'small',\n",
              " 'last',\n",
              " 'more',\n",
              " 'afraid',\n",
              " 'long',\n",
              " 'sad',\n",
              " 'long',\n",
              " 'dear',\n",
              " 'cunning',\n",
              " 'old',\n",
              " 'whole',\n",
              " 'fifth',\n",
              " 'ready',\n",
              " 'useful',\n",
              " 'such',\n",
              " 'nonsense!â\\x80\\x9d',\n",
              " 'poor',\n",
              " 'story!â\\x80\\x9d',\n",
              " 'little',\n",
              " 'old',\n",
              " 'young',\n",
              " 'little',\n",
              " 'particular',\n",
              " 'ready',\n",
              " 'little',\n",
              " 'remarkable',\n",
              " 'old',\n",
              " 'high',\n",
              " 'various',\n",
              " 'melancholy',\n",
              " 'good',\n",
              " 'dear',\n",
              " 'poor',\n",
              " 'lonely',\n",
              " 'low',\n",
              " 'spirited',\n",
              " 'little',\n",
              " 'little',\n",
              " 'half',\n",
              " 'little',\n",
              " 'dear',\n",
              " 'white',\n",
              " 'little',\n",
              " 'angry',\n",
              " 'frightened',\n",
              " 'neat',\n",
              " 'little',\n",
              " 'bright',\n",
              " 'great',\n",
              " 'real',\n",
              " 'ready',\n",
              " 'tidy',\n",
              " 'little',\n",
              " 'tiny',\n",
              " 'white',\n",
              " 'little',\n",
              " 'interesting',\n",
              " 'sure',\n",
              " 'large',\n",
              " 'iâ\\x80\\x99m',\n",
              " 'tired',\n",
              " 'tiny',\n",
              " 'little',\n",
              " 'thing!â\\x80\\x9d',\n",
              " 'drunk',\n",
              " 'â\\x80\\x9cthatâ\\x80\\x99s',\n",
              " 'drunk',\n",
              " 'much!â\\x80\\x9d',\n",
              " 'late',\n",
              " 'other',\n",
              " 'last',\n",
              " 'more',\n",
              " 'me?â\\x80\\x9d',\n",
              " 'little',\n",
              " 'magic']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMiUrTNyJfLp"
      },
      "source": [
        "#To import a couter\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFlRnL7GJncE",
        "outputId": "03df8904-399f-4a88-c4a8-30b530b255dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "aliceAdjs[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'good'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB3vk1ABKKUW"
      },
      "source": [
        "aliceAdjsLemmas = [word for word in aliceAdjs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQg8JKefM5zg"
      },
      "source": [
        "# The long way of the above\n",
        "aliceAdjs = []\n",
        "for token in aliceDoc:\n",
        "  if token.pos_ == 'ADJ': \n",
        "    aliceAdjs.append(token.lemma_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE6SdSf_LCmW",
        "outputId": "72755b7a-bf72-43fb-9385-936c08469b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(aliceAdjs[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBdLiyp7NlY_"
      },
      "source": [
        "###POS and Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgz-sQ3HLSQU"
      },
      "source": [
        "def commonPos(pos, doc=aliceDoc):\n",
        "  \"\"\" Given a POS like \"ADJ,\" return a list\n",
        "  of the most common oneas for the text. \"\"\"\n",
        "  onlyPos = [word.lemma for word in doc if word.pos_==pos]\n",
        "  return Counter(onlyPos).most_common(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MYSH1rqLz7w",
        "outputId": "a88a0dba-1f3f-4478-ae08-7d377172dc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "commonPos('NOUN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8885804376230376864, 72),\n",
              " (12398297404960798361, 71),\n",
              " (2473243759842082748, 66),\n",
              " (6878210874361030284, 54),\n",
              " (257396040179354343, 48),\n",
              " (8419699711262724776, 47),\n",
              " (665090814712476250, 42),\n",
              " (3094151635273811273, 34),\n",
              " (10690717480206833971, 32),\n",
              " (11139402979604626973, 31),\n",
              " (2991803765722746262, 31),\n",
              " (11916616154811659322, 30),\n",
              " (8705013900692850835, 30),\n",
              " (12670099585788978990, 28),\n",
              " (1608482186128794349, 27),\n",
              " (779410287755165804, 27),\n",
              " (8664790716774201746, 21),\n",
              " (5439657043933447811, 21),\n",
              " (8259674898417220296, 21),\n",
              " (2944576840756700711, 20)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2MbitzDNqdm"
      },
      "source": [
        "def commonPos(pos, doc=aliceDoc):\n",
        "  \"\"\" Given a POS like \"ADJ,\" return a list\n",
        "  of the most common oneas for the text. \"\"\"\n",
        "  onlyPos = [word.lemma for word in doc if word.pos_==tag]\n",
        "  return Counter(onlyPos).most_common(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Scm_0d0NtE4",
        "outputId": "07b14bb3-d05c-46cb-8c9a-11adc177d629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "commonTag('NN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-ef26f0bee6d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommonTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'commonTag' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBQ3OmWMOEFy"
      },
      "source": [
        "### Named Entity recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJX5kTnEOIa6",
        "outputId": "765b4400-1e92-4e13-eeba-f4bf9ef0a85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(aliceDoc.ents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsIBQTkoOYfD",
        "outputId": "6ced5aa7-488e-4b1e-e734-3b2180738b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for ent in aliceDoc.ents[100:200]:\n",
        "  print(ent, ent.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ada PERSON\n",
            "Iâm PERSON\n",
            "Mabel PERSON\n",
            "Iâm PERSON\n",
            "four CARDINAL\n",
            "five CARDINAL\n",
            "twelve CARDINAL\n",
            "four CARDINAL\n",
            "six CARDINAL\n",
            "thirteen CARDINAL\n",
            "four CARDINAL\n",
            "seven CARDINAL\n",
            "twenty CARDINAL\n",
            "London GPE\n",
            "Paris GPE\n",
            "Paris GPE\n",
            "Mabel ORG\n",
            "â_How ORG\n",
            "â\r\n",
            "\r\n",
            " ORG\n",
            "Nile LOC\n",
            "jaws!â\r\n",
            "\r\n",
            "\r\n",
            "âIâm PERSON\n",
            "Alice PERSON\n",
            "Mabel PERSON\n",
            "Iâm Mabel PERSON\n",
            "âCome PERSON\n",
            "dear!â\r\n",
            " PERSON\n",
            "âWho am PERSON\n",
            "first ORDINAL\n",
            "elseââbut ORG\n",
            "dear!â PERSON\n",
            "Alice PERSON\n",
            "here!â\r\n",
            "\r\n",
            " PERSON\n",
            "one CARDINAL\n",
            "Rabbitâs PERSON\n",
            "about two feet QUANTITY\n",
            "escape!â ORG\n",
            "Alice PERSON\n",
            "garden!â PERSON\n",
            "first ORDINAL\n",
            "Alice PERSON\n",
            "English NORP\n",
            "the\r\n",
            "sea LOC\n",
            "nine feet QUANTITY\n",
            "much!â PERSON\n",
            "Alice PERSON\n",
            "first ORDINAL\n",
            "Alice PERSON\n",
            "âO Mouse PERSON\n",
            "Alice PERSON\n",
            "Latin LANGUAGE\n",
            "mouseâO mouse!â PERSON\n",
            "English LANGUAGE\n",
            "Alice PERSON\n",
            "daresay PERSON\n",
            "French NORP\n",
            "William the Conqueror.â PERSON\n",
            "Alice PERSON\n",
            "âOÃ¹ est ma chatte?â ORG\n",
            "first ORDINAL\n",
            "French LANGUAGE\n",
            "The Mouse WORK_OF_ART\n",
            "pardon!â PERSON\n",
            "Alice PERSON\n",
            "cats!â PERSON\n",
            "âWould\r\n",
            " PERSON\n",
            "Alice PERSON\n",
            "Dinah PERSON\n",
            "Alice PERSON\n",
            "half CARDINAL\n",
            "faceâand GPE\n",
            "Alice PERSON\n",
            "Mouse PERSON\n",
            "again!â\r\n",
            "\r\n",
            " MONEY\n",
            "indeed!â PERSON\n",
            "Alice PERSON\n",
            "Alice PERSON\n",
            "thingsâI ORG\n",
            "half CARDINAL\n",
            "themâand ORG\n",
            "a hundred pounds QUANTITY\n",
            "dear!â PERSON\n",
            "Alice PERSON\n",
            "them!â ORG\n",
            "Alice PERSON\n",
            "youâll PERSON\n",
            "the\r\n",
            "birds LOC\n",
            "a\r\n",
            "Dodo PRODUCT\n",
            "Lory PERSON\n",
            "Alice\r\n",
            " PERSON\n",
            "CHAPTER III LAW\n",
            "first ORDINAL\n",
            "a few minutes TIME\n",
            "Alice PERSON\n",
            "Lory PERSON\n",
            "Alice PERSON\n",
            "Lory PERSON\n",
            "Mouse ORG\n",
            "âSit ORG\n",
            "the\r\n",
            "Mouse ORG\n",
            "Alice PERSON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOz7jhd9PFbJ",
        "outputId": "cf13736d-15fb-4748-f4a0-df15147d7165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#count the times a place appears\n",
        "Counter([ent.lemma_ for ent in aliceDoc.ents if ent.label_ == \"GPE\"]).most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('â\\x80\\x9cDo', 3),\n",
              " ('Iâ\\x80\\x99d', 3),\n",
              " ('â\\x80\\x9ca', 2),\n",
              " ('Paris', 2),\n",
              " ('â\\x80\\x9cSure', 2),\n",
              " ('New Zealand', 1),\n",
              " ('London', 1),\n",
              " ('faceâ\\x80\\x94and', 1),\n",
              " ('Morcar', 1),\n",
              " ('Mercia', 1),\n",
              " ('Northumbria', 1),\n",
              " ('Canterbury', 1),\n",
              " ('comfit', 1),\n",
              " ('know!â\\x80\\x9d', 1),\n",
              " ('Iâ\\x80\\x99m', 1),\n",
              " ('yetâ\\x80\\x94Oh', 1),\n",
              " ('knowâ\\x80\\x94and', 1),\n",
              " ('getâ\\x80\\x99', 1),\n",
              " ('watch!â\\x80\\x9d', 1),\n",
              " ('beheaded!â\\x80\\x9d', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyejmoEiPkZi",
        "outputId": "a2996319-ae75-4743-880f-0623b7f7bf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#counting the times a person appears:\n",
        "Counter([ent.lemma_ for ent in aliceDoc.ents if ent.label_ == \"PERSON\"]).most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Alice', 311),\n",
              " ('Hatter', 49),\n",
              " ('Iâ\\x80\\x99m', 24),\n",
              " ('â\\x80\\x9cWhat', 20),\n",
              " ('Queen', 13),\n",
              " ('Dinah', 10),\n",
              " ('youâ\\x80\\x99re', 7),\n",
              " ('Bill', 7),\n",
              " ('Footman', 7),\n",
              " ('Lory', 6),\n",
              " ('Rabbit', 5),\n",
              " ('Queenâ\\x80\\x99s', 5),\n",
              " ('that!â\\x80\\x9d', 4),\n",
              " ('indeed!â\\x80\\x9d', 4),\n",
              " ('â\\x80\\x9cthatâ\\x80\\x99s', 4),\n",
              " ('the Mock Turtle', 4),\n",
              " ('Beauâ\\x80\\x94ootiful Sooâ\\x80\\x94oop', 4),\n",
              " ('aliceâ\\x80\\x99s', 3),\n",
              " ('â\\x80\\x9cThey', 3),\n",
              " ('Rabbitâ\\x80\\x99s', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ecoO61OP0B9",
        "outputId": "ad8265eb-ad53-47f5-88c0-56da8f50ad02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#counting the times a work of art appears: (and so on depending on what we are counting)\n",
        "Counter([ent.lemma_ for ent in aliceDoc.ents if ent.label_ == \"WORK_OF_ART\"]).most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the Mock Turtle', 5),\n",
              " ('the Pool of Tears \\r\\n  chapter III', 1),\n",
              " ('a long tale \\r\\n  chapter IV', 1),\n",
              " ('the Mock Turtleâ\\x80\\x99s story', 1),\n",
              " ('the Mouse', 1),\n",
              " ('the Knave of Hearts', 1),\n",
              " ('the mock Turtle', 1),\n",
              " ('the White Rabbit', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYqdk3kpQDZF"
      },
      "source": [
        "take computational literacy analysis course? with Jonathan ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpHyDVFlRRji",
        "outputId": "60eb5a64-77de-44aa-c72b-d7556880f350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sent100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "she looked up, but it was all dark overhead; before her was another\n",
              "long passage, and the White Rabbit was still in sight, hurrying down\n",
              "it."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v9yIUQDRfLT",
        "outputId": "7cf9e6ee-bb8e-4b53-e8c1-c1d89bf984d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sent100[0].i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODnnlfm-RVWa"
      },
      "source": [
        "indices = []\n",
        "for word in aliceDoc:\n",
        "  if word.lemma_=='think':\n",
        "    indices.append(word.i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFJO3YeRRp1w"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjvG5euYR6nb"
      },
      "source": [
        "counts, bins = np.histogram(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1SZDpoqSMG9",
        "outputId": "480d1a1a-9a1a-4167-ed72-ddc13ec6ed52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16, 16, 12, 14, 15, 14, 13,  9, 10,  6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOYUJ-OySWgA",
        "outputId": "4a1aa216-fd79-465e-cd44-0c52f5e07e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bins"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  181.,  3515.,  6849., 10183., 13517., 16851., 20185., 23519.,\n",
              "       26853., 30187., 33521.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-D-MZT6SYHt"
      },
      "source": [
        "def plotWodsAcrssBook(needle):\n",
        "  indices = []\n",
        "  for word in aliceDoc:\n",
        "    try:\n",
        "      if word.lemma_==needle:\n",
        "        indices.append(word.i)\n",
        "    except:\n",
        "      continue\n",
        "    counts, bins = no.histogram(indices)\n",
        "    pd.Series(counts).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv5WJmerTc30",
        "outputId": "8dabf5fa-9661-45b6-efca-5f01022e073d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "plotWodsAcrssBook('cat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-7de3a149c030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotWodsAcrssBook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-d687576e0fb5>\u001b[0m in \u001b[0;36mplotWodsAcrssBook\u001b[0;34m(needle)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'no' is not defined"
          ]
        }
      ]
    }
  ]
}